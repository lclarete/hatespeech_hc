{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0954a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "# pre-processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Text preprocessing: remove stopwords using gensim\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "# models\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# testing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# pipeline \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3585a9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5668, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Hate.speech</th>\n",
       "      <th>Sexism</th>\n",
       "      <th>Body</th>\n",
       "      <th>Racism</th>\n",
       "      <th>Ideology</th>\n",
       "      <th>Homophobia</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Health</th>\n",
       "      <th>...</th>\n",
       "      <th>Thin.women</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>East.europeans</th>\n",
       "      <th>Africans</th>\n",
       "      <th>South.Americans</th>\n",
       "      <th>Brazilians</th>\n",
       "      <th>Migrants</th>\n",
       "      <th>Homossexuals</th>\n",
       "      <th>Thin.people</th>\n",
       "      <th>Ageing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"não come mel, morde marimbondo\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>não tem pinto, tem orgulho !</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  Hate.speech  Sexism  Body  Racism  \\\n",
       "0  \"não come mel, morde marimbondo\"            0       0     0       0   \n",
       "1      não tem pinto, tem orgulho !            0       0     0       0   \n",
       "\n",
       "   Ideology  Homophobia  Origin  Religion  Health  ...  Thin.women  Arabic  \\\n",
       "0         0           0       0         0       0  ...           0       0   \n",
       "1         0           0       0         0       0  ...           0       0   \n",
       "\n",
       "   East.europeans  Africans  South.Americans  Brazilians  Migrants  \\\n",
       "0               0         0                0           0         0   \n",
       "1               0         0                0           0         0   \n",
       "\n",
       "   Homossexuals  Thin.people  Ageing  \n",
       "0             0            0       0  \n",
       "1             0            0       0  \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/2019-05-28_portuguese_hate_speech_hierarchical_classification.csv\")\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68ea887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation using the default string library  \n",
    "\n",
    "# transform all tokens in the tweets to lower case.\n",
    "def preprocessing(text):\n",
    "    text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8183f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting X and y variables\n",
    "X = df.text\n",
    "y = df[\"Hate.speech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20048a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold crossvalidation (Chollet, 2017), combined with holdout validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd93ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(X, y, model, model_name, n_splits:int=10):\n",
    "    # kfold with 10 splits split\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # set a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    # metrics\n",
    "    scoring = ['accuracy', 'f1', 'f1_micro', 'f1_macro']\n",
    "    # cross validation\n",
    "    scores = cross_validate(pipeline, X, y, scoring=scoring, cv=kf)\n",
    "    \n",
    "    # format the results into a dataframe\n",
    "    results = pd.DataFrame(scores)\n",
    "    results['model_name'] = model_name\n",
    "    # save it into the results directory\n",
    "#     results.to_csv(f'data/results/{model_name}.csv')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd3fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'ComplementNB':ComplementNB(),\n",
    "    'LogisticRegression':LogisticRegression(),\n",
    "    'ForestClassifier':RandomForestClassifier(max_depth=4, n_estimators=150),\n",
    "    'xgboost': xgb.XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5866dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for k, v in models.items():\n",
    "    results = model_evaluate(X, y, v, k)\n",
    "    results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2248f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results = pd.concat(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e2eed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_f1_micro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.078757</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.848625</td>\n",
       "      <td>0.521511</td>\n",
       "      <td>0.848625</td>\n",
       "      <td>0.715797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ForestClassifier</th>\n",
       "      <td>0.270319</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.783345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783345</td>\n",
       "      <td>0.439256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.186008</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>0.865031</td>\n",
       "      <td>0.589457</td>\n",
       "      <td>0.865031</td>\n",
       "      <td>0.754347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.850224</td>\n",
       "      <td>0.020230</td>\n",
       "      <td>0.874913</td>\n",
       "      <td>0.657073</td>\n",
       "      <td>0.874913</td>\n",
       "      <td>0.790285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fit_time  score_time  test_accuracy   test_f1  \\\n",
       "model_name                                                          \n",
       "ComplementNB        0.078757    0.008462       0.848625  0.521511   \n",
       "ForestClassifier    0.270319    0.018754       0.783345  0.000000   \n",
       "LogisticRegression  0.186008    0.008745       0.865031  0.589457   \n",
       "xgboost             0.850224    0.020230       0.874913  0.657073   \n",
       "\n",
       "                    test_f1_micro  test_f1_macro  \n",
       "model_name                                        \n",
       "ComplementNB             0.848625       0.715797  \n",
       "ForestClassifier         0.783345       0.439256  \n",
       "LogisticRegression       0.865031       0.754347  \n",
       "xgboost                  0.874913       0.790285  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_results.groupby('model_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cc89b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search\n",
    "\n",
    "# # https://www.kaggle.com/code/carlosdg/xgboost-with-scikit-learn-pipeline-gridsearchcv/notebook\n",
    "# model = xgb.XGBClassifier()\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     ('standard_scaler', StandardScaler()), \n",
    "#     ('pca', PCA()), \n",
    "#     ('model', model)\n",
    "# ])\n",
    "\n",
    "# param_grid = {\n",
    "#     'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
    "#     'model__max_depth': [2, 3, 5, 7, 10],\n",
    "#     'model__n_estimators': [10, 100, 500],\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "# grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20015d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgBoost input\n",
    "# and we save the last layer before the classification to extract 50 dimensions as input to the xgBoost algorithm,7 which is a gradient boosting implementation from the Python library (Chen and Guestrin, 2016).\n",
    "# or xgBoost, the default parameter setting has been used, except for ‘eta’ and ‘gamma’. In this case, we conducted a grid search combining several values of both (eta: 0, 0.3, 1; and gamma: 0.1,1, 10) in order to obtain the optimal eta and gamma settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2154ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network\n",
    "\n",
    "# Methods provided by Keras are then used to map each token in the input to an embedding.\n",
    "# feature extraction: glove 300 dimentions\n",
    "# pre-trained Glove word embeddings with 300 dimensions for Portuguese (Hartmann et al., 2017). \n",
    "\n",
    "# classification: lstm\n",
    "# https://github.com/paulafortuna/twitter-hatespeech/blob/master/lstm.py\n",
    "\n",
    "# The architecture contains an embedding Layer with the weights from the word embeddings \n",
    "# extraction procedure, an additional LSTM layer with 50 dimensions, and dropouts at the end of both layers.\n",
    "\n",
    "# As loss function, we used binary crossentropy and for optimization Adam, 10 epochs and 128 for batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95eea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
