{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914b7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! export MACOSX_DEPLOYMENT_TARGET=10.9\n",
    "# ! pip install extremetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3af135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94adf551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mwydmuch/extremeText\n",
    "# https://arxiv.org/pdf/1810.11671v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "42576553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import extremeText\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "905b7780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5668, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Hate.speech</th>\n",
       "      <th>Sexism</th>\n",
       "      <th>Body</th>\n",
       "      <th>Racism</th>\n",
       "      <th>Ideology</th>\n",
       "      <th>Homophobia</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Health</th>\n",
       "      <th>...</th>\n",
       "      <th>Thin.women</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>East.europeans</th>\n",
       "      <th>Africans</th>\n",
       "      <th>South.Americans</th>\n",
       "      <th>Brazilians</th>\n",
       "      <th>Migrants</th>\n",
       "      <th>Homossexuals</th>\n",
       "      <th>Thin.people</th>\n",
       "      <th>Ageing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"não come mel, morde marimbondo\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>não tem pinto, tem orgulho !</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  Hate.speech  Sexism  Body  Racism  \\\n",
       "0  \"não come mel, morde marimbondo\"            0       0     0       0   \n",
       "1      não tem pinto, tem orgulho !            0       0     0       0   \n",
       "\n",
       "   Ideology  Homophobia  Origin  Religion  Health  ...  Thin.women  Arabic  \\\n",
       "0         0           0       0         0       0  ...           0       0   \n",
       "1         0           0       0         0       0  ...           0       0   \n",
       "\n",
       "   East.europeans  Africans  South.Americans  Brazilians  Migrants  \\\n",
       "0               0         0                0           0         0   \n",
       "1               0         0                0           0         0   \n",
       "\n",
       "   Homossexuals  Thin.people  Ageing  \n",
       "0             0            0       0  \n",
       "1             0            0       0  \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/2019-05-28_portuguese_hate_speech_hierarchical_classification.csv')\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d52e3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b6eb8bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "pt_stopwords = stopwords.words('portuguese')\n",
    "def stop_words(value):\n",
    "    for text in value:      \n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "    return tokens\n",
    "\n",
    "# df['text'] = df.text.apply(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9622f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "    # remove mentions\n",
    "    # lower case\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6e10a8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        \"não come mel, morde marimbondo\"\n",
       "1                            não tem pinto, tem orgulho !\n",
       "2       Não vê essa merda de Crepúsculo! Pra isso temo...\n",
       "3       não da tapa na bundinha, da cotovelada nas cos...\n",
       "4       o diminutivo INHO não acompanha a trajetória d...\n",
       "                              ...                        \n",
       "5663    Na minha sala só tem viado e sapatão  e a cois...\n",
       "5664    PARABENS SAPATÃO SDDS @attomiter https://t.co/...\n",
       "5665    RT @toquedeveludo: Agora um poema:\\nEu sou sap...\n",
       "5666    O mundo das sapatao é mais ligado do que eu im...\n",
       "5667    Gente, sapatão é uma coisa q me assusta https:...\n",
       "Name: text, Length: 5668, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3303349e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [``]\n",
       "1        [!]\n",
       "2        [.]\n",
       "3        [!]\n",
       "4        [.]\n",
       "        ... \n",
       "5663     [o]\n",
       "5664     [c]\n",
       "5665      []\n",
       "5666     [a]\n",
       "5667     [g]\n",
       "Name: text, Length: 5668, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.apply(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d09271f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Hate-speech</th>\n",
       "      <th>Sexism</th>\n",
       "      <th>Body</th>\n",
       "      <th>Racism</th>\n",
       "      <th>Ideology</th>\n",
       "      <th>Homophobia</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Health</th>\n",
       "      <th>...</th>\n",
       "      <th>Africans</th>\n",
       "      <th>South-Americans</th>\n",
       "      <th>Brazilians</th>\n",
       "      <th>Migrants</th>\n",
       "      <th>Homossexuals</th>\n",
       "      <th>Thin-people</th>\n",
       "      <th>Ageing</th>\n",
       "      <th>label_total</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>extremeText_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[``]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['``']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[!]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['!']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[.]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[!]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['!']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[.]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text Hate-speech Sexism  Body Racism Ideology Homophobia Origin Religion  \\\n",
       "0  [``]        None   None  None   None     None       None   None     None   \n",
       "1   [!]        None   None  None   None     None       None   None     None   \n",
       "2   [.]        None   None  None   None     None       None   None     None   \n",
       "3   [!]        None   None  None   None     None       None   None     None   \n",
       "4   [.]        None   None  None   None     None       None   None     None   \n",
       "\n",
       "  Health  ... Africans South-Americans Brazilians Migrants Homossexuals  \\\n",
       "0   None  ...     None            None       None     None         None   \n",
       "1   None  ...     None            None       None     None         None   \n",
       "2   None  ...     None            None       None     None         None   \n",
       "3   None  ...     None            None       None     None         None   \n",
       "4   None  ...     None            None       None     None         None   \n",
       "\n",
       "  Thin-people Ageing label_total label_binary extremeText_label  \n",
       "0        None   None                        0            ['``']  \n",
       "1        None   None                        0             ['!']  \n",
       "2        None   None                        0             ['.']  \n",
       "3        None   None                        0             ['!']  \n",
       "4        None   None                        0             ['.']  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ccb356c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex\n",
    "# essa, esta, essas, estas, esse, esses, este, estes: es[st]?*\n",
    "stopwords_manual = ['http?', 'mais', 'is?o', 'es[st]?*', 'quan[dt]?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "23cdd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data should follow this format from extreme text\n",
    "\n",
    "train_data_format = \"\"\"\n",
    "__label__mariadb-galera __label__mariadb55-mariadb __label__mysql55-mysql mariadb mariadb mysql solaris vulnerability oracle mysql server users availability vectors keys oracle com technetwork topics security html http secunia com http www oracle com technetwork topics security http lists security announce msg00016 html http www oracle com technetwork topics security html http secunia com http www securityfocus security gentoo glsa xml mariadb-galera mariadb55-mariadb-devel ruby-mysql openshift-origin-cartridge-mysql rh-mariadb100-mariadb mariadb-apb-role query-mysql mariadb55-mariadb-test rh-mysql57-mysql rh-mariadb101-mariadb rh-mysql56-mysql mysql mysql-connector-java mariadb55-mariadb-bench mysql55-mysql mysql-apb-role mysql mariadb55-mariadb-server mysql-binuuid-rails rh-mysql80-mysql com.github.brandtg switchboard-mysql rh-mariadb102-mariadb mariadb mariadb55-mariadb rhn-solaris-bootstrap mariadb55-mariadb-libs\n",
    "\"\"\"\n",
    "# https://github.com/automated-library/ICPC_2022_Automated-Identification-of-Libraries-from-Vulnerability-Data/tree/main/extremeText/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1d1fb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3k/n8m_c1vj5gb6gyfmb_vsyf9w0000gn/T/ipykernel_5136/1666610618.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns.str.replace('.', '-')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None    5668\n",
       "Name: Sexism, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace \".\" with \"-\"\n",
    "df.columns = df.columns.str.replace('.', '-')\n",
    "\n",
    "cols = df.columns\n",
    "cols = ['Hate-speech', 'Sexism', 'Body', 'Racism', 'Ideology', 'Homophobia', 'Origin', 'Religion', 'Health', 'OtherLifestyle', 'Aborting-women', 'Agnostic', 'Argentines', 'Asians', 'Autists', 'Black-Women', 'Blond-women', 'Brazilians-women', 'Chinese', 'Criminals', 'Egyptians', 'Fat-people', 'Football-players-women', 'Gamers', 'Homeless', 'Homeless-women', 'Indigenous', 'Iranians', 'Japaneses', 'Jews', 'Jornalists', 'Latins', 'Left-wing-ideology', 'Men-Feminists', 'Mexicans', 'Muslims-women', 'Nordestines', 'Old-people', 'Polyamorous', 'Poor-people', 'Rural-people', 'Russians', 'Sertanejos', 'Street-artist', 'Ucranians', 'Vegetarians', 'White-people', 'Young-people', 'Old-women', 'Ugly-people', 'Venezuelans', 'Angolans', 'Black-people', 'Disabled-people', 'Fat-women', 'Feminists', 'Gays', 'Immigrants', 'Islamists', 'Lesbians', 'Men', 'Muslims', 'Refugees', 'Trans-women', 'Travestis', 'Women', 'Bissexuals', 'Transexuals', 'Ugly-women', 'Thin-women', 'Arabic', 'East-europeans', 'Africans', 'South-Americans', 'Brazilians', 'Migrants', 'Homossexuals', 'Thin-people', 'Ageing']\n",
    "\n",
    "def label_value(value, col):\n",
    "    label = f'__label__{col}'\n",
    "    if value == 1:\n",
    "        return label\n",
    "    else:\n",
    "        return \"None\"\n",
    "    \n",
    "for i in cols:\n",
    "    df[i] = df[i].apply(label_value, args=(i,))\n",
    "    \n",
    "df.Sexism.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2200ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_total'] = df[cols].agg(''.join, axis=1)\n",
    "df['label_total'] = df['label_total'].str.replace(\"None\", \"\")\n",
    "df['label_total'] = df['label_total'].str.replace(\"__label\", \" __label\")\n",
    "df['label_total'] = df['label_total'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35e18d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like not all data has a label\n",
    "# this function identify the one who got a label, and the one who don't\n",
    "def identify_label(value):\n",
    "    if \"__label\" in value:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "17a8bbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5668\n",
       "Name: label_binary, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_binary'] = df['label_total'].apply(identify_label)\n",
    "df['label_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad67386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extremeText_label'] = df['label_total'].astype(str) + df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e2598d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ['``']\n",
       "1        ['!']\n",
       "2        ['.']\n",
       "3        ['!']\n",
       "4        ['.']\n",
       "         ...  \n",
       "5663     ['o']\n",
       "5664     ['c']\n",
       "5665        []\n",
       "5666     ['a']\n",
       "5667     ['g']\n",
       "Name: extremeText_label, Length: 5668, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['extremeText_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5c137d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = list(df[df['label_binary'] == 1]['extremeText_label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3d429e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train_hs.txt', 'a') as the_file:\n",
    "    for item in labeled_data:\n",
    "        the_file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00d043",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "84fd4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE train, test split\n",
    "# create a new one with this: http://scikit.ml/stratification.html\n",
    "# X = df.copy()\n",
    "# del X['Hate.speech']\n",
    "# del X['text']\n",
    "\n",
    "# y = df['Hate.speech']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2ba53201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split data\n",
    "# https://datascience.stackexchange.com/questions/45174/how-to-use-sklearn-train-test-split-to-stratify-data-for-multi-label-classificat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ed6141be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = make_multilabel_classification(n_samples=300, n_classes=100, n_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c27bdb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 20)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2496c4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 100)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6306cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X,Y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d782eda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 6., 1., ..., 6., 2., 3.],\n",
       "       [0., 1., 2., ..., 2., 1., 2.],\n",
       "       [6., 1., 0., ..., 4., 2., 1.],\n",
       "       ...,\n",
       "       [3., 4., 0., ..., 2., 0., 3.],\n",
       "       [1., 3., 4., ..., 4., 4., 4.],\n",
       "       [2., 2., 6., ..., 4., 2., 1.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "05bb4280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Hate-speech</th>\n",
       "      <th>Sexism</th>\n",
       "      <th>Body</th>\n",
       "      <th>Racism</th>\n",
       "      <th>Ideology</th>\n",
       "      <th>Homophobia</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Health</th>\n",
       "      <th>...</th>\n",
       "      <th>Africans</th>\n",
       "      <th>South-Americans</th>\n",
       "      <th>Brazilians</th>\n",
       "      <th>Migrants</th>\n",
       "      <th>Homossexuals</th>\n",
       "      <th>Thin-people</th>\n",
       "      <th>Ageing</th>\n",
       "      <th>label_total</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>extremeText_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[``]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['``']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[!]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['!']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[.]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[!]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['!']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[.]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>[o]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['o']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>[c]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['c']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>[a]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['a']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>[g]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['g']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5668 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text Hate-speech Sexism  Body Racism Ideology Homophobia Origin  \\\n",
       "0     [``]        None   None  None   None     None       None   None   \n",
       "1      [!]        None   None  None   None     None       None   None   \n",
       "2      [.]        None   None  None   None     None       None   None   \n",
       "3      [!]        None   None  None   None     None       None   None   \n",
       "4      [.]        None   None  None   None     None       None   None   \n",
       "...    ...         ...    ...   ...    ...      ...        ...    ...   \n",
       "5663   [o]        None   None  None   None     None       None   None   \n",
       "5664   [c]        None   None  None   None     None       None   None   \n",
       "5665    []        None   None  None   None     None       None   None   \n",
       "5666   [a]        None   None  None   None     None       None   None   \n",
       "5667   [g]        None   None  None   None     None       None   None   \n",
       "\n",
       "     Religion Health  ... Africans South-Americans Brazilians Migrants  \\\n",
       "0        None   None  ...     None            None       None     None   \n",
       "1        None   None  ...     None            None       None     None   \n",
       "2        None   None  ...     None            None       None     None   \n",
       "3        None   None  ...     None            None       None     None   \n",
       "4        None   None  ...     None            None       None     None   \n",
       "...       ...    ...  ...      ...             ...        ...      ...   \n",
       "5663     None   None  ...     None            None       None     None   \n",
       "5664     None   None  ...     None            None       None     None   \n",
       "5665     None   None  ...     None            None       None     None   \n",
       "5666     None   None  ...     None            None       None     None   \n",
       "5667     None   None  ...     None            None       None     None   \n",
       "\n",
       "     Homossexuals Thin-people Ageing label_total label_binary  \\\n",
       "0            None        None   None                        0   \n",
       "1            None        None   None                        0   \n",
       "2            None        None   None                        0   \n",
       "3            None        None   None                        0   \n",
       "4            None        None   None                        0   \n",
       "...           ...         ...    ...         ...          ...   \n",
       "5663         None        None   None                        0   \n",
       "5664         None        None   None                        0   \n",
       "5665         None        None   None                        0   \n",
       "5666         None        None   None                        0   \n",
       "5667         None        None   None                        0   \n",
       "\n",
       "     extremeText_label  \n",
       "0               ['``']  \n",
       "1                ['!']  \n",
       "2                ['.']  \n",
       "3                ['!']  \n",
       "4                ['.']  \n",
       "...                ...  \n",
       "5663             ['o']  \n",
       "5664             ['c']  \n",
       "5665                []  \n",
       "5666             ['a']  \n",
       "5667             ['g']  \n",
       "\n",
       "[5668 rows x 83 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c59e68",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "https://github.com/automated-library/ICPC_2022_Automated-Identification-of-Libraries-from-Vulnerability-Data/blob/main/extremeText/extremetext_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29d6d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/automated-library/ICPC_2022_Automated-Identification-of-Libraries-from-Vulnerability-Data/blob/main/extremeText/extremetext_train.py\n",
    "\n",
    "def model_training(train_data):\n",
    "    # train_supervised uses the same arguments and defaults as the fastText/extremeText cli\n",
    "\n",
    "    print(\"Supervised Training\")\n",
    "    # default supervised training\n",
    "    # model = extremeText.train_supervised(\n",
    "    #     input=train_data, epoch=100, lr=1.0, wordNgrams=2, verbose=3, minCount=1,\n",
    "    # )\n",
    "\n",
    "    # paper supervised training\n",
    "    model = extremeText.train_supervised(\n",
    "        input=train_data, epoch=100, lr=0.05, verbose=3, wordNgrams=2, minCount=1, l2=0.003, arity=2, dim=100, tfidfWeights=True\n",
    "    )\n",
    "    model.save_model(\"./model/xt_supervised.bin\")\n",
    "    return model\n",
    "\n",
    "    # print(\"Quantization\")\n",
    "    #\n",
    "    # model.quantize(input=train_data, qnorm=True, retrain=True, cutoff=100000)\n",
    "    #\n",
    "    # model.save_model(\"model/xt_quantized.ftz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6fa84fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_training(train_data = \"./dataset/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0e428021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "  Model: sup, loss: softmax\n",
      "  Features: TF-IDF weights, buckets: 2000000\n",
      "\n",
      "  Update: SGD, lr: 0.050000, L2: 0.003000, dims: 100, epochs: 100, neg: 5\n",
      "Reading input file ...\n",
      "Read 0M words\n",
      "Number of documents: 8036\n",
      "Number of words: 5887\n",
      "Number of labels: 911\n",
      "  Input: 2005887 x 100 (765M)\n",
      "Setting up loss layer ...\n",
      "  Output: 911 x 100 (0M)\n",
      "Starting 12 threads ...\n",
      "Progress: 100.0% words/sec/thread:   68492 lr:  0.000000 loss:  5.210812 ETA:   0h 0m\n",
      "Saving model ...\n"
     ]
    }
   ],
   "source": [
    "model = model_training(train_data = \"./data/train_hs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2fc8e4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__Hate-speech',), array([-0.83271313]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('O mundo das sapatao é mais ligado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c57d49cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5887"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cb7b3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_4words = []\n",
    "for word in model.get_words():\n",
    "    if len(word) > 3:\n",
    "        l_4words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "08b6325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5220"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l_4words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1cabf65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " 'https',\n",
       " 'mulher',\n",
       " 'burra',\n",
       " 'gorda',\n",
       " 'mais',\n",
       " 'feia',\n",
       " 'sapatão',\n",
       " 'para',\n",
       " 'fufas',\n",
       " 'homem',\n",
       " 'pode',\n",
       " 'sapatao',\n",
       " 'como',\n",
       " 'mulheres',\n",
       " 'isso',\n",
       " 'quando',\n",
       " 'refugiados',\n",
       " 'essa',\n",
       " 'feia,',\n",
       " 'muito',\n",
       " 'gente',\n",
       " 'mesmo',\n",
       " 'coisa',\n",
       " 'minha',\n",
       " 'cara',\n",
       " 'gorda,',\n",
       " 'mundo',\n",
       " 'contra',\n",
       " 'quem',\n",
       " 'aqui',\n",
       " 'gosta',\n",
       " 'quer',\n",
       " 'nada',\n",
       " '#MulherDeVerdade',\n",
       " 'fica',\n",
       " 'você',\n",
       " 'tudo',\n",
       " 'assim',\n",
       " 'acha',\n",
       " 'feminista',\n",
       " 'fazer',\n",
       " 'eles',\n",
       " 'ainda',\n",
       " '@homemdeverdade',\n",
       " 'menos',\n",
       " 'sabe',\n",
       " 'branco',\n",
       " 'nunca',\n",
       " 'Mulher',\n",
       " 'racismo',\n",
       " 'esse',\n",
       " 'toda',\n",
       " 'porque',\n",
       " 'homens',\n",
       " 'quero',\n",
       " 'todo',\n",
       " 'MULHER',\n",
       " 'falando',\n",
       " 'sempre',\n",
       " 'feliz',\n",
       " 'vejo',\n",
       " 'refugiados.',\n",
       " 'vida',\n",
       " 'está',\n",
       " 'fala',\n",
       " 'pelo',\n",
       " 'igual',\n",
       " 'pessoas',\n",
       " 'chama',\n",
       " 'tenho',\n",
       " 'chamar',\n",
       " 'puta',\n",
       " 'parece',\n",
       " 'falar',\n",
       " 'sobre',\n",
       " 'seria',\n",
       " 'pela',\n",
       " 'negro',\n",
       " 'hora',\n",
       " 'casa',\n",
       " 'feminismo',\n",
       " 'dizer',\n",
       " 'feministas',\n",
       " 'não,',\n",
       " 'onde',\n",
       " 'depois',\n",
       " 'podem',\n",
       " 'burra,',\n",
       " 'mulher,',\n",
       " 'machista',\n",
       " 'anos',\n",
       " 'estou',\n",
       " 'ficar',\n",
       " 'viado',\n",
       " 'Como',\n",
       " 'aceita',\n",
       " 'hoje',\n",
       " 'acho',\n",
       " 'sentindo',\n",
       " 'dizem',\n",
       " 'linda',\n",
       " 'dela',\n",
       " 'passar',\n",
       " 'GORDA',\n",
       " 'agora',\n",
       " 'HOMEM',\n",
       " 'merda',\n",
       " 'fosse',\n",
       " 'essas',\n",
       " 'tanto',\n",
       " 'usar',\n",
       " 'cada',\n",
       " 'filho',\n",
       " 'entrar',\n",
       " 'existe',\n",
       " 'sinto',\n",
       " '@editorahumanas',\n",
       " 'disse',\n",
       " 'chamando',\n",
       " 'mina',\n",
       " 'outra',\n",
       " 'crianças',\n",
       " 'Orgulho',\n",
       " 'seus',\n",
       " 'feia.',\n",
       " 'sair',\n",
       " 'orgulho',\n",
       " 'estão',\n",
       " 'negros',\n",
       " 'todas',\n",
       " 'FEIA',\n",
       " 'melhor',\n",
       " 'esta',\n",
       " 'bonita',\n",
       " 'lugar',\n",
       " 'deus',\n",
       " 'gays',\n",
       " 'sapatão,',\n",
       " 'dessa',\n",
       " 'menina',\n",
       " 'apenas',\n",
       " 'queria',\n",
       " 'receber',\n",
       " 'tinha',\n",
       " 'pras',\n",
       " 'foto',\n",
       " '\"essa',\n",
       " 'pior',\n",
       " 'todos',\n",
       " 'esses',\n",
       " 'brasil',\n",
       " 'ninguém',\n",
       " 'também',\n",
       " 'tempo',\n",
       " 'achando',\n",
       " 'odeio',\n",
       " 'dinheiro',\n",
       " 'porra',\n",
       " 'feia\"',\n",
       " 'namorada',\n",
       " 'fico',\n",
       " 'querem',\n",
       " 'fufas,',\n",
       " 'quanto',\n",
       " 'fora',\n",
       " 'tava',\n",
       " '#JoaquinResponde',\n",
       " 'conhece',\n",
       " 'países',\n",
       " 'país',\n",
       " 'povo',\n",
       " 'bandido',\n",
       " 'roupa',\n",
       " 'Burra',\n",
       " 'bunda',\n",
       " 'elas',\n",
       " 'claro',\n",
       " 'cabeça',\n",
       " 'amigas',\n",
       " 'somos',\n",
       " 'pega',\n",
       " '@JOAQUINVOLTOU',\n",
       " 'fazendo',\n",
       " 'estar',\n",
       " 'olha',\n",
       " 'amiga',\n",
       " 'vocês',\n",
       " 'amor',\n",
       " 'ficam',\n",
       " 'posso',\n",
       " 'deve',\n",
       " 'demasiado',\n",
       " 'dele',\n",
       " 'volta',\n",
       " 'ganhar',\n",
       " 'saber',\n",
       " 'maioria',\n",
       " 'família',\n",
       " 'macho',\n",
       " 'burra.',\n",
       " 'coisas',\n",
       " '@PastorMalafaia',\n",
       " 'sendo',\n",
       " 'pros',\n",
       " 'precisa',\n",
       " 'outras',\n",
       " 'chamou',\n",
       " 'Agora',\n",
       " 'demais',\n",
       " 'falei',\n",
       " 'mulher.',\n",
       " 'maior',\n",
       " 'dizendo',\n",
       " 'bonita,',\n",
       " 'Isso',\n",
       " 'aguento',\n",
       " 'escola',\n",
       " 'aquela',\n",
       " 'favor',\n",
       " 'CARA',\n",
       " 'antes',\n",
       " 'deixar',\n",
       " 'mimimi',\n",
       " 'pois',\n",
       " 'sabem',\n",
       " 'aquele',\n",
       " 'http',\n",
       " 'futebol',\n",
       " 'casal',\n",
       " 'ideologia',\n",
       " 'culpa',\n",
       " '#PAZ',\n",
       " 'Portugal',\n",
       " 'umas',\n",
       " 'gênero',\n",
       " 'Europa',\n",
       " 'nome',\n",
       " 'NADA',\n",
       " '@direitafalando',\n",
       " 'magra,',\n",
       " 'meninas',\n",
       " 'racista',\n",
       " '#orgulhohetero',\n",
       " 'outro',\n",
       " 'cabelo',\n",
       " 'mulher\"',\n",
       " 'forma',\n",
       " 'Islão',\n",
       " 'pretos',\n",
       " 'frente',\n",
       " 'realmente',\n",
       " 'banheiro',\n",
       " 'nenhum',\n",
       " 'valor',\n",
       " 'merda,',\n",
       " 'tanta',\n",
       " 'acreditar',\n",
       " 'piranha',\n",
       " 'pegar',\n",
       " 'alguém',\n",
       " 'gordo',\n",
       " 'nenhuma',\n",
       " 'vale',\n",
       " 'massa',\n",
       " 'namorar',\n",
       " 'seguir',\n",
       " 'entre',\n",
       " 'ouvir',\n",
       " 'lado',\n",
       " 'amigos',\n",
       " 'isto',\n",
       " 'morre',\n",
       " 'vontade',\n",
       " 'BURRA',\n",
       " 'esquerda',\n",
       " 'gorda\"',\n",
       " 'termina',\n",
       " 'letras',\n",
       " 'pensar',\n",
       " 'seja',\n",
       " 'liga',\n",
       " '@maathbz',\n",
       " 'MAIS',\n",
       " '\"feliz',\n",
       " 'mulher!',\n",
       " 'numa',\n",
       " 'peitos',\n",
       " 'burro',\n",
       " 'devem',\n",
       " 'criminosos',\n",
       " 'chata',\n",
       " 'tiver',\n",
       " 'grávida',\n",
       " 'certeza',\n",
       " 'quiser',\n",
       " 'terrorista',\n",
       " 'sim,',\n",
       " 'inteligente',\n",
       " 'mesma',\n",
       " 'falam',\n",
       " 'comida',\n",
       " 'monte',\n",
       " 'ISSO',\n",
       " 'Angola',\n",
       " 'adoro',\n",
       " 'atenção',\n",
       " 'consegue',\n",
       " 'verdade',\n",
       " 'filha',\n",
       " 'moral',\n",
       " 'meses',\n",
       " 'branca',\n",
       " 'você,',\n",
       " 'Brasil.',\n",
       " 'acabou',\n",
       " 'Mais',\n",
       " 'linda,',\n",
       " '@jpintocoelho60',\n",
       " 'brancos',\n",
       " 'nossa',\n",
       " 'feminazi',\n",
       " 'poder',\n",
       " 'trans',\n",
       " 'esperar',\n",
       " 'minhas',\n",
       " 'gosto',\n",
       " 'vira',\n",
       " 'sentir',\n",
       " 'pele',\n",
       " 'duas',\n",
       " 'PROBLEMA',\n",
       " 'JUSTIÇA',\n",
       " 'preto',\n",
       " 'hetero',\n",
       " 'PODE',\n",
       " 'TIRAR',\n",
       " 'corpo',\n",
       " 'foda',\n",
       " 'enquanto',\n",
       " 'parabéns',\n",
       " 'inverso',\n",
       " 'ESSA',\n",
       " 'nascer',\n",
       " 'então',\n",
       " 'paga',\n",
       " 'cultura',\n",
       " 'filhos',\n",
       " 'meio',\n",
       " '\"refugiados\"',\n",
       " 'APROPRIAÇÃO',\n",
       " 'MULHERES',\n",
       " 'causa',\n",
       " 'GOSTO',\n",
       " 'MINHA',\n",
       " 'muçulmanos',\n",
       " 'Hetero',\n",
       " 'curso',\n",
       " 'VERGONHA',\n",
       " 'maravilhosa,',\n",
       " 'dias',\n",
       " 'resto',\n",
       " 'bate',\n",
       " 'Quando',\n",
       " 'adao',\n",
       " 'menino',\n",
       " 'preconceito',\n",
       " 'super',\n",
       " 'Pode',\n",
       " 'sexo',\n",
       " 'problema.',\n",
       " 'kkkkk',\n",
       " 'nosso',\n",
       " 'direito',\n",
       " 'querer',\n",
       " 'qualquer',\n",
       " 'dia,',\n",
       " 'gorda...',\n",
       " 'mães',\n",
       " 'sapatão\"',\n",
       " 'sala',\n",
       " 'movimento',\n",
       " 'puta,',\n",
       " 'Oriente',\n",
       " 'desses',\n",
       " 'Quem',\n",
       " 'maria',\n",
       " 'EUA.',\n",
       " 'lavar',\n",
       " 'Mulheres',\n",
       " 'terroristas',\n",
       " 'sapatao.',\n",
       " '@girlslkgirls',\n",
       " 'cortar',\n",
       " 'homicídio',\n",
       " 'NUNCA',\n",
       " '@caiquepala',\n",
       " 'doente',\n",
       " 'familia',\n",
       " 'sofre',\n",
       " 'estes',\n",
       " 'tradicional',\n",
       " 'Sapatão',\n",
       " 'disso',\n",
       " 'manifestação',\n",
       " 'sofrendo',\n",
       " 'mariquice',\n",
       " 'chineses',\n",
       " 'gostosa.',\n",
       " 'respeito',\n",
       " 'desculpa',\n",
       " 'SAPATÃO',\n",
       " 'temos',\n",
       " 'nada.',\n",
       " 'falsos',\n",
       " 'falta',\n",
       " 'defende',\n",
       " 'manobra',\n",
       " 'FELIZ',\n",
       " 'gostosas',\n",
       " 'graças',\n",
       " 'será',\n",
       " 'ficou',\n",
       " 'mim,',\n",
       " 'Lugar',\n",
       " 'casa,',\n",
       " 'PARA',\n",
       " 'caralho',\n",
       " 'PHOTO',\n",
       " 'celular',\n",
       " '@otmar03',\n",
       " 'sido',\n",
       " 'única',\n",
       " 'prima',\n",
       " 'conseguem',\n",
       " 'CHEGA',\n",
       " 'muçulmano',\n",
       " 'desejo',\n",
       " 'mandar',\n",
       " 'perfil',\n",
       " 'continuar',\n",
       " 'HOJE',\n",
       " 'inferno',\n",
       " 'muita',\n",
       " 'negras',\n",
       " 'manda',\n",
       " 'lindas',\n",
       " 'sapatão?',\n",
       " 'vezes',\n",
       " 'criou',\n",
       " 'fotos',\n",
       " 'FEMINISTAS',\n",
       " 'FEMINISTA',\n",
       " 'AINDA',\n",
       " 'amar',\n",
       " '#JOAQUINRESPONDE',\n",
       " 'caso',\n",
       " 'Islão,',\n",
       " 'chamam',\n",
       " 'queremos',\n",
       " 'não!',\n",
       " 'lembra',\n",
       " 'assume',\n",
       " 'veja',\n",
       " 'obrigada',\n",
       " 'tirar',\n",
       " 'gostam',\n",
       " '#Islão',\n",
       " 'preciso',\n",
       " '@LeoLimaDuarte',\n",
       " 'acaba',\n",
       " 'lindo',\n",
       " 'macho,',\n",
       " 'pergunta',\n",
       " 'textão',\n",
       " 'imigrantes,',\n",
       " 'bando',\n",
       " 'pobre',\n",
       " 'miga',\n",
       " 'Basta',\n",
       " 'querendo',\n",
       " 'construção',\n",
       " 'achar',\n",
       " 'odeiam',\n",
       " 'algo',\n",
       " 'gastar',\n",
       " 'Roberta',\n",
       " 'lavando',\n",
       " 'peluda',\n",
       " 'capital',\n",
       " 'hein',\n",
       " 'cota',\n",
       " 'comigo',\n",
       " 'entram',\n",
       " '[9/3',\n",
       " 'gostar',\n",
       " 'feminazis',\n",
       " 'história',\n",
       " 'kkkkkk',\n",
       " 'pais',\n",
       " 'lugar.',\n",
       " 'sejam',\n",
       " 'velha',\n",
       " 'humor',\n",
       " 'sente',\n",
       " 'SAIA',\n",
       " 'MAQUIAGEM',\n",
       " 'estava',\n",
       " 'suas',\n",
       " 'destruir',\n",
       " 'professora',\n",
       " 'Brasil',\n",
       " 'começar',\n",
       " 'inclusive',\n",
       " 'difícil',\n",
       " '@JhullyMelo79',\n",
       " 'março',\n",
       " 'pênis',\n",
       " 'BRANCO',\n",
       " 'vida.',\n",
       " 'mortos',\n",
       " 'machismo',\n",
       " 'Feliz',\n",
       " 'acabar',\n",
       " 'sabia',\n",
       " 'jogo',\n",
       " 'estaria',\n",
       " 'mostrar',\n",
       " 'gostosa',\n",
       " 'emprego',\n",
       " 'tivesse',\n",
       " 'Melhor',\n",
       " 'rede',\n",
       " 'vermelho',\n",
       " 'problemas',\n",
       " 'tomar',\n",
       " 'VOCÊ',\n",
       " 'normal',\n",
       " 'idiota',\n",
       " 'pessoa',\n",
       " '@SpOAB',\n",
       " 'SAPATAO',\n",
       " 'apanha',\n",
       " 'decote',\n",
       " 'desde',\n",
       " 'mesquita',\n",
       " 'dirigir,',\n",
       " '#DiadaMulher',\n",
       " 'outros',\n",
       " 'balada',\n",
       " 'MERDA',\n",
       " 'falo',\n",
       " 'SABE',\n",
       " 'ontem',\n",
       " 'gorda.',\n",
       " 'pensa',\n",
       " 'pensei',\n",
       " 'Fufas',\n",
       " 'marido',\n",
       " 'pessoal',\n",
       " 'feminista?',\n",
       " 'vagabunda',\n",
       " '@GABRIELPlNHEIRO',\n",
       " 'problema',\n",
       " 'rola',\n",
       " 'olhos',\n",
       " 'feministo',\n",
       " 'pede',\n",
       " 'lidar',\n",
       " 'legal',\n",
       " 'série',\n",
       " 'inteiro',\n",
       " 'twitter',\n",
       " 'carne',\n",
       " 'metade',\n",
       " 'escrota',\n",
       " 'nessa',\n",
       " 'luta',\n",
       " 'Deus,',\n",
       " '#MasterChefBR',\n",
       " 'vender',\n",
       " 'grupo',\n",
       " 'levar',\n",
       " 'video',\n",
       " 'FAZER',\n",
       " 'quiser.',\n",
       " 'suficiente',\n",
       " 'reclama',\n",
       " 'terá',\n",
       " 'primeiro',\n",
       " 'diferença',\n",
       " 'deveria',\n",
       " 'voltar',\n",
       " 'andar',\n",
       " 'burca',\n",
       " 'nordeste',\n",
       " 'refugiados,',\n",
       " 'deveriam',\n",
       " 'também.',\n",
       " 'DEIXA',\n",
       " 'Sapatao',\n",
       " 'teresa',\n",
       " 'imprensa',\n",
       " 'mulheres.',\n",
       " 'hoje,',\n",
       " 'adianta',\n",
       " '#SerMulherÉ',\n",
       " 'estupro',\n",
       " 'come',\n",
       " 'BRASIL',\n",
       " 'significado',\n",
       " 'entendi',\n",
       " 'cuidado',\n",
       " 'piada',\n",
       " 'veste',\n",
       " 'país.',\n",
       " 'sapatão.',\n",
       " 'raiva',\n",
       " 'Nada',\n",
       " 'passou',\n",
       " 'vadia',\n",
       " 'GENTE',\n",
       " 'pensando',\n",
       " 'piadinhas',\n",
       " 'ruim',\n",
       " 'cara,',\n",
       " 'importa',\n",
       " 'começa',\n",
       " '@elpais_brasil',\n",
       " 'cego',\n",
       " 'igualdade\"',\n",
       " '#meuamigosecreto',\n",
       " 'socialismo',\n",
       " 'ache',\n",
       " 'mulher?',\n",
       " 'Então',\n",
       " 'dois',\n",
       " 'vinda',\n",
       " 'acaso',\n",
       " 'arrota',\n",
       " 'perguntar',\n",
       " 'FIO,',\n",
       " 'GRANDE',\n",
       " 'suco',\n",
       " 'vieram',\n",
       " 'Bomba',\n",
       " 'país,',\n",
       " 'Internacional',\n",
       " 'aceitar',\n",
       " 'risco',\n",
       " 'opinião',\n",
       " 'Coincidência??????',\n",
       " '@roxmo',\n",
       " 'direita',\n",
       " 'loira',\n",
       " 'respondi',\n",
       " '@realDonaldTrump',\n",
       " '#ImigraçãoInvasora',\n",
       " 'viagem!',\n",
       " 'Esse',\n",
       " 'Consequência',\n",
       " 'anos.',\n",
       " 'evidências!',\n",
       " 'médio',\n",
       " 'ouvido',\n",
       " 'defesa',\n",
       " 'Somos',\n",
       " 'morta',\n",
       " 'feito',\n",
       " 'menina.',\n",
       " 'aquilo..amanhã',\n",
       " 'palavra',\n",
       " 'Mundo',\n",
       " '#NaoAIdeologiaDeGenero',\n",
       " 'SHARIA',\n",
       " 'QUEREMOS',\n",
       " 'islâmicos',\n",
       " 'imigração',\n",
       " 'propõe',\n",
       " '2516/15',\n",
       " 'apoio',\n",
       " 'começando',\n",
       " '@marisa_lobo',\n",
       " 'AHAHAH',\n",
       " 'juro',\n",
       " '#Fufas',\n",
       " 'paras',\n",
       " 'disto',\n",
       " 'recebe',\n",
       " 'filho.',\n",
       " 'prints',\n",
       " 'acham',\n",
       " 'galeria',\n",
       " 'últimas',\n",
       " 'expor',\n",
       " 'bonita.',\n",
       " 'frase',\n",
       " 'atrás',\n",
       " 'compre\"',\n",
       " 'conheça',\n",
       " 'judeus',\n",
       " 'motivo',\n",
       " 'devia',\n",
       " 'lutam',\n",
       " 'mana',\n",
       " 'beber',\n",
       " 'AZUL',\n",
       " 'OLHO',\n",
       " 'BORA!1!!!!',\n",
       " 'sitio',\n",
       " 'coração',\n",
       " 'levo',\n",
       " '*ignores*',\n",
       " 'excepto',\n",
       " 'quintal',\n",
       " 'Aceitar',\n",
       " 'GORDO,',\n",
       " 'quero,',\n",
       " 'trabalhar',\n",
       " 'trabalho,',\n",
       " 'trata',\n",
       " 'feminista\"',\n",
       " 'BRANCAS',\n",
       " 'identidade',\n",
       " 'LOURAS',\n",
       " 'certo,',\n",
       " 'CONDENANDO',\n",
       " 'NEGRO.',\n",
       " 'virgem',\n",
       " 'procura',\n",
       " 'musica',\n",
       " 'amanha',\n",
       " 'RACISMO,',\n",
       " 'aceitam',\n",
       " 'ricos',\n",
       " '@New_Delia',\n",
       " 'países.',\n",
       " 'chorando',\n",
       " '#DiaDaMulher',\n",
       " 'QUANDO?',\n",
       " 'FEMINISTO',\n",
       " 'chamada',\n",
       " 'pegando',\n",
       " 'peito',\n",
       " 'viram',\n",
       " 'homossexual.',\n",
       " 'DEFENDE',\n",
       " 'desse',\n",
       " 'inteira',\n",
       " 'gente,',\n",
       " 'decentes',\n",
       " 'serem',\n",
       " 'Disney',\n",
       " 'Bela',\n",
       " 'consigo',\n",
       " '\"gorda\"',\n",
       " '\"feminazi\"',\n",
       " 'automaticamente',\n",
       " 'namora',\n",
       " 'fofas',\n",
       " 'pimenta',\n",
       " 'insta',\n",
       " 'squad',\n",
       " 'queridas',\n",
       " 'putas',\n",
       " 'olhando',\n",
       " 'falou',\n",
       " 'errado,',\n",
       " '<333',\n",
       " 'pena',\n",
       " 'ignorante',\n",
       " 'bonitinha',\n",
       " 'saudade',\n",
       " 'postar',\n",
       " '\"pra',\n",
       " 'refugiado',\n",
       " 'QUEM',\n",
       " 'acolhendo',\n",
       " 'ajudando',\n",
       " 'peso',\n",
       " 'livre.',\n",
       " 'tratem',\n",
       " 'doendo',\n",
       " 'livro',\n",
       " '\"fufas\"',\n",
       " 'preocupam...',\n",
       " 'Olha',\n",
       " 'PRETO',\n",
       " 'homem,',\n",
       " 'PAREM',\n",
       " 'pediu',\n",
       " 'maneiras',\n",
       " 'empregada',\n",
       " 'negra',\n",
       " 'terra!',\n",
       " '@srdeabo',\n",
       " '@CapitalismoOP',\n",
       " 'amiguinha',\n",
       " 'existem',\n",
       " 'arruma',\n",
       " 'Porque',\n",
       " 'presta\"',\n",
       " 'TODA',\n",
       " 'pelas',\n",
       " 'abusadas',\n",
       " 'estuprador',\n",
       " 'burra\"',\n",
       " 'horrível',\n",
       " 'Pára',\n",
       " 'brasileira',\n",
       " 'vamos',\n",
       " 'kkkkkkk',\n",
       " 'babaca',\n",
       " 'arrumar',\n",
       " 'vários',\n",
       " 'internacional',\n",
       " 'sério',\n",
       " 'ouvi',\n",
       " '#twittealgomuitoantigo',\n",
       " 'machão',\n",
       " 'entender',\n",
       " 'ônibus',\n",
       " 'Ideologia',\n",
       " 'infantis.',\n",
       " 'porto\"',\n",
       " 'várias',\n",
       " '\"fufas',\n",
       " 'mexe.',\n",
       " 'atiram-se',\n",
       " 'preconceito,',\n",
       " 'pagando',\n",
       " 'nossa,',\n",
       " 'Cultura',\n",
       " 'agenda',\n",
       " 'Esquerda',\n",
       " 'verdadeiras',\n",
       " 'completamente',\n",
       " 'INCOMPATÍVEIS',\n",
       " 'nossas,',\n",
       " 'mesmo!',\n",
       " 'cristãos',\n",
       " '#vipdirecto',\n",
       " 'houve',\n",
       " '@joaomhenrique',\n",
       " 'Aqui',\n",
       " '@aloaloads',\n",
       " 'mostra',\n",
       " 'adeus',\n",
       " 'anoes',\n",
       " 'região',\n",
       " 'shemales',\n",
       " 'terra',\n",
       " 'simao',\n",
       " 'tem.',\n",
       " 'fiquei',\n",
       " 'melhores',\n",
       " '@Felipebastos022',\n",
       " 'doença',\n",
       " 'chegar',\n",
       " 'catinga',\n",
       " 'grande',\n",
       " 'bonito',\n",
       " 'sociedade',\n",
       " 'usam',\n",
       " 'argumento',\n",
       " '\"como',\n",
       " 'nascimento',\n",
       " '#Oscars',\n",
       " 'cona',\n",
       " '@RitaBranco02',\n",
       " 'troca',\n",
       " 'dentro',\n",
       " 'Quer',\n",
       " 'lixo',\n",
       " 'opa,',\n",
       " 'CONTRA',\n",
       " 'violência',\n",
       " 'ódio',\n",
       " 'anda',\n",
       " 'seres',\n",
       " '@t4keshy',\n",
       " 'ANOS',\n",
       " 'querida',\n",
       " 'fígado',\n",
       " 'gira',\n",
       " 'aula',\n",
       " 'Feminismo',\n",
       " 'voce',\n",
       " 'Punheta,',\n",
       " 'fufas.',\n",
       " 'feminino',\n",
       " 'mereço',\n",
       " 'qualidades',\n",
       " 'esquerdopatas.',\n",
       " 'arranjar...',\n",
       " 'coitada.',\n",
       " 'chamava',\n",
       " 'prefere',\n",
       " 'assistem',\n",
       " 'estará',\n",
       " 'Lary',\n",
       " 'cuida,',\n",
       " 'Lailão',\n",
       " 'sexual',\n",
       " 'curto',\n",
       " 'youtuber',\n",
       " 'reclamar',\n",
       " 'conheceu',\n",
       " 'bebê',\n",
       " 'droga,',\n",
       " 'monstro',\n",
       " 'sei,',\n",
       " 'Porto',\n",
       " 'fotografar',\n",
       " 'deixou',\n",
       " 'amor,',\n",
       " 'África',\n",
       " 'desenho',\n",
       " 'saudades',\n",
       " 'questão,',\n",
       " 'porém',\n",
       " 'pequeno',\n",
       " 'idades',\n",
       " 'parecem',\n",
       " 'travesti',\n",
       " 'beijo',\n",
       " 'sozinha',\n",
       " 'Parabéns',\n",
       " 'LOUÇA',\n",
       " 'LAVAR',\n",
       " 'apesar',\n",
       " 'algum',\n",
       " 'deixa',\n",
       " 'ligado',\n",
       " 'tempo,',\n",
       " 'opção',\n",
       " 'tudo.',\n",
       " 'fato',\n",
       " 'RICO',\n",
       " 'ajudar',\n",
       " 'saia',\n",
       " 'nojo!',\n",
       " 'machistas',\n",
       " 'liberdade',\n",
       " 'esqueci',\n",
       " 'gayzada',\n",
       " 'NEGRO',\n",
       " 'R(ap)efugees\"?',\n",
       " '\"Welcome',\n",
       " 'hábitos',\n",
       " 'mudam',\n",
       " 'nesse',\n",
       " 'medo',\n",
       " 'papel',\n",
       " 'andam',\n",
       " 'quis',\n",
       " 'SELF',\n",
       " 'violações!',\n",
       " 'Menina',\n",
       " 'pagar',\n",
       " 'tive',\n",
       " 'tudo,',\n",
       " 'contratar',\n",
       " 'tratar',\n",
       " 'Imprensa',\n",
       " 'Bolsonaro',\n",
       " 'preocupa-se',\n",
       " 'cristaos',\n",
       " 'real,',\n",
       " 'pedi',\n",
       " 'PERFEITA',\n",
       " 'Presidente',\n",
       " 'iludida',\n",
       " 'fazem',\n",
       " 'perseguidos',\n",
       " '@sofiakalap',\n",
       " 'crimes',\n",
       " 'existe,',\n",
       " '@Egocentricpapi',\n",
       " 'MERRDA',\n",
       " 'esquece',\n",
       " 'cometidos',\n",
       " '@BiaMontezumaMF',\n",
       " 'babar',\n",
       " 'POLITICAMENTE',\n",
       " 'biologicamente',\n",
       " 'norte',\n",
       " 'CORRETO',\n",
       " 'nega',\n",
       " 'PELUDO',\n",
       " 'SUVACO',\n",
       " 'paciência',\n",
       " 'vendo',\n",
       " 'independente',\n",
       " '@LeNaZZo',\n",
       " 'FAZENDO',\n",
       " 'GOSTA',\n",
       " 'VOLTOU',\n",
       " 'EUROPEU',\n",
       " 'APANHAR',\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_4words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17338baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
